# Documentation:
# https://amulet-docs.azurewebsites.net/main/advanced/51_distributed.html#
# https://amulet-docs.azurewebsites.net/config_file.html

description: Training Tokenized ViT

environment:
  registry: commondockerimages.azurecr.io
  username: commondockerimages
  image: climate_pretraining:latest

code:
  local_dir: $CONFIG_DIR/../

target:
  service: aml
  name: v100x8-scus

storage:
  data:
    storage_account_name: weatherdatastorage2
    # storage_account_name: weatherml1836488272
    container_name: datasets
    mount_dir: /mnt/data
    mount_options: ["--file-cache-timeout-in-seconds=0"]

# some environment variables to ease up setting of jobs
env_defaults:
  NODES: 1
  GPUS: 8

search:
  job_template:
    name: tokenized_vit_5.625deg_finetune_time_conditioned_{auto:10s} # ex: simple_job_lr_05
    sku: ${NODES}x32G${GPUS} # ex: G1
    process_count_per_node: ${GPUS}
    submit_args:
      env: { AZUREML_COMPUTE_USE_COMMON_RUNTIME: True }
      container_args:
        shm_size: 650g
    command:
      - pip install -e .
      - export MKL_THREADING_LAYER=GNU
      - python src/train_vit_time_conditioned.py --config configs/finetune_vit_time_conditioned.yaml
        --trainer.devices=${GPUS} --trainer.num_nodes=${NODES} --trainer.strategy=ddp
        --trainer.max_epochs=50
        --data.root_dir=/mnt/data/5.625deg_new_equally_np_all_levels/
        --data.out_variables={vars}
        --data.max_predict_range=168 --data.random_lead_time=True --data.hrs_each_step=1
        --data.buffer_size=5000
        --data.num_workers=1 --data.batch_size=16
        --model.net.decoder_depth=2 --model.net.learn_pos_emb=True --model.net.img_size=[32,64]
        --model.net.time_history=1
        --model.net.out_vars={vars}
        --model.net.channel_agg='attention'
        --model.net.init_mode='small'
        --model.net.patch_size=2
        --model.net.depth={depth}
        --model.net.embed_dim={dim}
        --model.net.num_heads={heads}
        --model.lr={lr}
        --model.net.drop_path=0.1
        --model.net.drop_rate=0.1
        --model.weight_decay=1e-5
        --model.pretrained_path=/mnt/data/checkpoints/data_scaling/mpi_tai_awi_hammoz_cmcc/last.ckpt

  type: grid
  max_trials: 80
  params:
    - name: vars
      spec: discrete
      values: ['z_500', 't_850', 't2m', 'u10', 'v10']
    - name: depth
      spec: discrete
      values: [8]
    - name: dim
      spec: discrete
      values: [1024]
    - name: heads
      spec: discrete
      values: [16]
    - name: lr
      spec: discrete
      values: [5e-7]